# 模型评估与选择

## 过拟合
过拟合是指 学习模型独训练样本预测的很好，但是对新样本预测很差的现象，通常是由于学习模型的能力过于强大，以至于把训练样本的一些特点当做了一般性质。
	`也就是说当样本中出现离群点，异常点的时候，学习能力太过强大，把这些异常值也学习了，过犹不及的现象。`
	过拟合是无法彻底避免的，只能缓解，模型选择就是要只在避免过拟合并提高模型的预测能力。

## 评估方法
通常用测试误差来近似模型的泛化（广泛化）误差，

### 留出法（hold-out）
留出法直接将数据集D划分为两个互斥的部分，其中一部分为训练集S,另一部分用做测试集T。
通常训练集合测试集的比例为70%：30%，同时，训练集测试集的划分也应该有两个注意事项：

- 尽可能保持数据分布的一致性，避免因为数据划分过程中引入额外的偏差而对最终的结果产生影响，在分类任务中，保留类别比例的采样方法称为‘**分层采样**’（stratifed sampling）
- 采用若干次随机划分避免单次使用留出法的不稳定性。

### 交叉验证法
交叉验证法现将数据集D划分为k个大小相似的互斥子集，每采用k-1个子集的并集作为训练集，那么剩下的子集就作为测试集，对k次训练和测试，最终返回k个测试结果的均值，又称为**k折交叉验证**（k-fold cross validation）。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828135457286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAxODY3MQ==,size_16,color_FFFFFF,t_70)

为了减少因样本划分带来的偏差，通常重复p次以上不同的划分，最终结果就是p次k折交叉验证的结果的均值。

### 留一法（leave-one-out ,LOO）
留一发是k折交叉验证中k=m（m等于样本数）的特殊情况，也就是说每次只用一个样本作为测试集，该方法计算所占用的空间较大。

### 自助法（bootstrapping）
自助法是以自助采样为基础（有放回采样），每次随机从D中挑选出一个样本，放入D‘，然后将样本放回到D中，重复了m次之后，也就得到了包含m个样本的数据集。
样本在m次采样中始终不被采取到的概率为【(1-1/m)的n 次幂】，当m趋于无穷取极限为1/e = 0.368。也就是说D中约有36.8%的样本未出现在D’中，于是将D’用作训练集，D/D'用作测试集，这样仍然会有m个训练样本，但是约有1/3未出现在训练集中的样本被作为测试集了。
优点：自助法在数据集较小，难以有限划分训练/测试集时很有用
缺点：然而自助法会改变初始数据集的分布，会引入估计偏差。

## 性能度量
二分类问题常用的评价指标为**查准率**和**查全率**。根据预测正确与否，可以将样例分为以下四种：
- TP（True positive，真正例） -- 将正类预测为正类数
- FP（False positive，假正例） -- 将反类预测为正类数
- TN（True negative，真反例） -- 将反类预测为反类数
- FN（False negative，假反例）-- 将正类预测为反类数

1、查准率 （precision，精确率）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828141017684.png)

​		即将正类预测为正类数与预测为正类的总数的比值。
2、查全率（recall，召回率）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828141311752.png)

​		即将正类预测为正类数与正类总数的比值

查准率和查全率是一对矛盾的度量，查准率和查全率的调和平均为：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828141540324.png)

当查全率和查准率都高的时候，F也会高。

## 泛化能力
泛化误差（Generaliztion error）是学得的模型`f`对位置数据预测的误差.
对测试样本x，令y’为x在数据集中的标记，y是x 的真实标记，f(x;D)为训练集D上学得到模型f在x上的预测输出。
- 学习算法的期望输出为：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828141938279.png)

- 偏差是期望输出与真实标记之间的误差：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828142135569.png)

- 方差是预测值与期望输出之间的方差：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828142221363.png)

- 噪声是标记与真实标记之间的方差：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828142311281.png)

偏差度量了学习算法的期望预测与真实结果之间的偏离程度，刻画了学习算法本身的拟合能力。
方差度量了同样大小的训练集变动所导致的学习性能的变化，刻画了数据扰动造成的影响。
噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下届，刻画了学习问题本身的难度。
算法的期望泛化误差E(f;D)，可以分解为偏差、方差和噪声之和

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828142626454.png)