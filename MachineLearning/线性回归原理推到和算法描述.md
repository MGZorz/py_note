# 线性回归原理推到和算法描述

## 概念
线性回归（Linear Regression）是一种通过属性的线性组合来进行预测的线性模型，其目的是找到一条直线或者平面或者更高维度的超平面，使得预测值与真实值之间的误差最小化。
## 特点
- 优点：结果具有很好的可解释性（只管表达了各属性在预测中的重要性），计算熵补不复杂。
- 缺点：对非线性数据拟合不好
- 适用的数据类型：数值型和标称型数据

## 原理推导

​		为了推导模型，在假设数据满足线性摸模型的条件下，可以设定线性模型为：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828150540674.png)

其中x1特征为商品的大小，x2特征为商品的价格。

模型假定好之后，我们把训练数据代入上面的设定的模型中，可以通过模型预测一个样本最终值；

![1566976071328](C:/Users/admin/AppData/Roaming/Typora/typora-user-images/1566976071328.png)

然后样本真实值`y`和模型训练预测的值之间是有误差`ε`的，在假设训练样本的数据量很大的时候，根据中心极限定理，可以得到`∑ε` 满足`(μ,δ²)`高斯分布的；由于方程式有截距项，故可以使用`μ=0`，也就满足于`（0，δ²）`的高斯分布。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828151401347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAxODY3MQ==,size_16,color_FFFFFF,t_70)

对于每一个样本x而言，代入到`P(y|x;θ)`都会得到一个y的概率，因为设定样本都是独立同分布的，也就是说彼此之间没有任何影响，对其求**最大似然估计**.

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155153546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAxODY3MQ==,size_16,color_FFFFFF,t_70)

进行化简：

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019082815524264.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAxODY3MQ==,size_16,color_FFFFFF,t_70)

以上就得到了回归的损失函数最小二乘法的公式。

> 对上面进行一个总结：线性回归，根据大数定律和中心极限定理假定样本无穷大的时候，其真实值和预测值的误差`ε`的加和，和服从`μ=0，方差=δ²`的高斯分布独立同分布，然后把`ε =y-Øx`代入公式中，化简就可以得到线性回归的损失函数了



接下来对损失函数进行优化，使得损失函数最小化。

第一种方法为矩阵法，不过需要满足矩阵可逆的条件。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155259141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAxODY3MQ==,size_16,color_FFFFFF,t_70)

然后对其求偏导，只要找到一阶导数为0的位置，就能找到最优解。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155323342.png)

（ps:在第三行的`-2w`后的X少写了个转置T）

令偏导为0，会得到：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155416361.png)

当X是可逆的，得到：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155434167.png)

当X不可逆的话，会有很多个解。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828155449944.png)





参考至：<https://blog.csdn.net/lisi1129/article/details/68925799>