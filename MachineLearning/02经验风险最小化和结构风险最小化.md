
# 经验风险最小化与结构风险最小化

## 损失函数和风险函数
损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏
常用的损失函数有以下几种：

- 0-1损失函数（0-1 loss function）
	
	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105132924.png)
	
- 平方损失函数（quadratic loss function）

	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105250729.png)

- 绝对损失函数（absolute loss function）

	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105343662.png)

- 对数损失函数（logarithmic）或者对数似然损失函数（log-likelihood）

	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105451198.png)

	损失函数值越小，模型就越好，由于模型的输入输出（x,y）是随机变量，遵循俩呢分布P(x,y)，所有损失函数的期望是：

	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105625521.png)

- 这是理论上的模型f(x)关于联合分布P(x,y)的期望损失，称为**期望风险**。

	然而，联合分布P(x,y)是未知的，期望风险也就不能计算，可以近似为$f(x)$训练数据集的平均损失，也就是**经验风险（empirical risk）**,即：

	![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828105904895.png)

	根据大数定律，当样本容量N无限大,趋于无穷是，经验风险也就趋于期望风险，但是现实中的训练样本数目有限，用经验风险来估计期望风险往往不理想，要对经验风险进行一定的矫正，也就是形成**结构风险**。

## 经验风险最小化，与结构风险最小化

### 经验风险最小化（empirical risk minimization,ERM）
​	经验风险最小化的策略认为，经验风险最小的模型是最优的模型：

![](https://img-blog.csdnimg.cn/20190828110445920.png)

当样本容量足够大时，经验风险最小化能保证很好的学习效果，比如，极大似然估计（就是经验风险最小化的例子，当模型是条件概率分布，损失函数是对数损失函数是，经验风险最小化就等价于极大似然估计）

但是当样本容量很小的时候，经验风险最小化容易导致“过拟合”。

### 结构风险最小化（structural  minimization,SRM）

​	结构风险最小化是为了防止过拟合提出来的策略，结构风险最小化等价于正则化（regulariztion）。**结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或者惩罚项(penalty term)**。结构风险的定义为：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828111106483.png)

​	其中就`J(f)`是模型复杂度的函数，`λ≧0`是系数，用来权衡经验风险和模型复杂度。

​	结构风险最小化策略认为结构风险最小的模型就是最优模型：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828111351778.png)

结构风险小需要经验风险和模型复杂度同时都小，结构风险小的模型往往对训练数据以及位置的测试数据都有较好的预测。

​	比如，贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation.MAP）就是结构风险最小化的一个例子，当模型是条件概率分布、损失函数是对数损失函数，模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

