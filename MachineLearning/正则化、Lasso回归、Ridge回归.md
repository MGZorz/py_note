# 正则化、Lasso回归、Ridge回归

## 过拟合

当样本特征很多，但是样本的数量很少的时候，模型容易进入过拟合的状态，样本数量少，一旦样本中出现了异常值或者离群点之后，模型会拼命想拟合异常的值，会导致预测的数值和真实的数值之间误差很大，也就是过犹不及的状态。
为了尽可能的避免过拟合的状态，一般有两种方法：
- 减少特征数量（人工选择重要的特征进行保留，不过会丢失部分信息）
- 正则化（L1正则和L2正则）--> 也就是减少特征参数$w$的数量级

## 正则化（Regularization）

正则化就是结构风险（损失函数+正则化项）最小化策略的体现，是在经验风险（平均损失函数）后面加一个正则化项。
作用是选择经济风险和模型复杂度同时较小的模型。

它能防止过拟合的原理：正则化项一般是模型复杂度的单调递增函数，二经验风险负责最小化误差，使得模型偏差尽可能小，经验风险越小，模型越复杂，正则化项的值越大。要使正则化项很小，那么模型的复杂度就要受到限制，那么也就会防止过拟合的发生了。

